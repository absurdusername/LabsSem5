{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code mostly copied from chapter 2 of _Advanced Analytics with PySpark_ \n",
    "\n",
    "To download the dataset \n",
    "```shell\n",
    "$ mkdir linkage\n",
    "$ cd linkage/\n",
    "$ curl -L -o donation.zip https://bit.ly/1Aoywaq\n",
    "$ unzip donation.zip\n",
    "$ unzip 'block_*.zip'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/04 20:19:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path = 'data/linkage/block*.csv'\n",
    "df = spark.read.csv(path, header=True, nullValue='?', inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cache the DataFrame\n",
    "\n",
    "[\"Explaining the mechanics of Spark caching\"](https://luminousmen.com/post/explaining-the-mechanics-of-spark-caching) -- great article explaining why and how Spark DataFrames are cached\n",
    "\n",
    "The first action run after `df.cache()` will take its time (including overhead of caching). All subsequent actions will be fast it seems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.18 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "513 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "df.cache()\n",
    "\n",
    "%timeit -n 1 -r 1 df.count() # slow\n",
    "%timeit -n 1 -r 1 df.count() # fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create summary statistics for matches and non-matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def pivot(source_df):\n",
    "    \"\"\"Return a pivoted summary of `source_df`.\"\"\"\n",
    "\n",
    "    # convert to pandas DataFrame\n",
    "    pd_df = source_df.toPandas()\n",
    "\n",
    "    # pivot\n",
    "    pd_df = pd_df.set_index('summary').transpose().reset_index()\n",
    "    pd_df = pd_df.rename(columns={'index':'field'})\n",
    "\n",
    "    # convert to Spark DataFrame\n",
    "    result_df = spark.createDataFrame(pd_df)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+------------------+--------------------+---+-----+\n",
      "|       field|count|              mean|              stddev|min|  max|\n",
      "+------------+-----+------------------+--------------------+---+-----+\n",
      "|        id_1|20931| 34575.72117911232|   21950.31285196913|  5|99946|\n",
      "|        id_2|20931| 51259.95939037791|   24345.73345377519|  6|99996|\n",
      "|cmp_fname_c1|20922|0.9973163859635038| 0.03650667584833679|0.0|  1.0|\n",
      "|cmp_fname_c2| 1333|0.9898900320318176| 0.08251973727615237|0.0|  1.0|\n",
      "|cmp_lname_c1|20931|0.9970152595958817|0.043118807533945126|0.0|  1.0|\n",
      "|cmp_lname_c2|  475| 0.969370167843852| 0.15345280740388917|0.0|  1.0|\n",
      "|     cmp_sex|20931| 0.987291577086618| 0.11201570591216435|  0|    1|\n",
      "|      cmp_bd|20925|0.9970848267622461| 0.05391487659807981|  0|    1|\n",
      "|      cmp_bm|20925|0.9979450418160095|0.045286127452170664|  0|    1|\n",
      "|      cmp_by|20925|0.9961290322580645| 0.06209804856731055|  0|    1|\n",
      "|     cmp_plz|20902|0.9584250310975027| 0.19962063345931919|  0|    1|\n",
      "+------------+-----+------------------+--------------------+---+-----+\n",
      "\n",
      "+------------+-------+--------------------+--------------------+---+------+\n",
      "|       field|  count|                mean|              stddev|min|   max|\n",
      "+------------+-------+--------------------+--------------------+---+------+\n",
      "|        id_1|5728201|  33319.913548075565|  23665.760130330676|  1| 99980|\n",
      "|        id_2|5728201|   66643.44259218557|  23599.551728241313| 30|100000|\n",
      "|cmp_fname_c1|5727203|  0.7118634802175091| 0.38908060096985553|0.0|   1.0|\n",
      "|cmp_fname_c2| 102365|  0.8988473514090158| 0.27272090294010215|0.0|   1.0|\n",
      "|cmp_lname_c1|5728201|  0.3131380113364304|  0.3322812130572686|0.0|   1.0|\n",
      "|cmp_lname_c2|   1989| 0.16295544855122532|  0.1930236663528703|0.0|   1.0|\n",
      "|     cmp_sex|5728201|  0.9548833918362851| 0.20755988859217375|  0|     1|\n",
      "|      cmp_bd|5727412|  0.2216425149788421|  0.4153518275558732|  0|     1|\n",
      "|      cmp_bm|5727412|   0.486995347986141|  0.4998308940493865|  0|     1|\n",
      "|      cmp_by|5727412|  0.2199230647280133|  0.4141943267142977|  0|     1|\n",
      "|     cmp_plz|5715387|0.002043781112285135|0.045161979893625206|  0|     1|\n",
      "+------------+-------+--------------------+--------------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match_stats = pivot(df.where(df.is_match == True).describe())\n",
    "miss_stats = pivot(df.where(df.is_match == False).describe())\n",
    "\n",
    "match_stats.show()\n",
    "miss_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute how much each field differs for matches versus non-matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "First select relevant features\n",
    "\n",
    "What makes a good feature?\n",
    "- Has different values for matches and non-matches\n",
    "- Available most of the time (not null for most instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------------+\n",
      "|       field|occurances|               delta|\n",
      "+------------+----------+--------------------+\n",
      "|     cmp_plz| 5736289.0|  0.9563812499852176|\n",
      "|cmp_lname_c2|    2464.0|  0.8064147192926266|\n",
      "|      cmp_by| 5748337.0|  0.7762059675300512|\n",
      "|      cmp_bd| 5748337.0|   0.775442311783404|\n",
      "|cmp_lname_c1| 5749132.0|  0.6838772482594513|\n",
      "|      cmp_bm| 5748337.0|  0.5109496938298685|\n",
      "|cmp_fname_c1| 5748125.0|  0.2854529057459947|\n",
      "|cmp_fname_c2|  103698.0| 0.09104268062280174|\n",
      "|     cmp_sex| 5749132.0|0.032408185250332844|\n",
      "+------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match_stats.createOrReplaceTempView('match_stats')\n",
    "miss_stats.createOrReplaceTempView('miss_stats')\n",
    "\n",
    "query = '''\n",
    "    select A.field, A.count + B.count as occurances, A.mean - B.mean as delta\n",
    "    from match_stats A \n",
    "        inner join miss_stats B on A.field = B.field\n",
    "    where A.field not in ('id_1', 'id_2')\n",
    "    order by delta desc;\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"cmp_plz\", \"cmp_by\", \"cmp_bd\", \"cmp_lname_c1\", \"cmp_bm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|score|is_match|\n",
      "+-----+--------+\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "scored = df.fillna(0).\\\n",
    "    withColumn('score', expr(\" + \".join(features))).\\\n",
    "    select('score', 'is_match')\n",
    "\n",
    "scored.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate(threshold):\n",
    "    scored.selectExpr(f'score >= {threshold} as above', 'is_match').\\\n",
    "        groupBy('above').\\\n",
    "        pivot('is_match').\\\n",
    "        count().\\\n",
    "        show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold = 2\n",
      "+-----+-------+-----+\n",
      "|above|  false| true|\n",
      "+-----+-------+-----+\n",
      "| true| 596414|20931|\n",
      "|false|5131787| NULL|\n",
      "+-----+-------+-----+\n",
      "\n",
      "threshold = 3\n",
      "+-----+-------+-----+\n",
      "|above|  false| true|\n",
      "+-----+-------+-----+\n",
      "| true| 315213|20916|\n",
      "|false|5412988|   15|\n",
      "+-----+-------+-----+\n",
      "\n",
      "threshold = 4\n",
      "+-----+-------+-----+\n",
      "|above|  false| true|\n",
      "+-----+-------+-----+\n",
      "| true|    637|20871|\n",
      "|false|5727564|   60|\n",
      "+-----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(2, 5):\n",
    "    print(f'threshold = {t}')\n",
    "    tabulate(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
