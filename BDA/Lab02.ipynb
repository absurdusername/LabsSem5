{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71429483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    ('apple', 'red', 3),\n",
    "    ('banana', 'yellow', 5),\n",
    "    ('strawberry', 'red', 7)\n",
    "], schema='fruit string, color string, quantity int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ae46b",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6cd93bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+\n",
      "|     fruit|color|quantity|\n",
      "+----------+-----+--------+\n",
      "|     apple|  red|       3|\n",
      "|strawberry|  red|       7|\n",
      "+----------+-----+--------+\n",
      "\n",
      "+----------+------+--------+------------------------------+\n",
      "|     fruit| color|quantity|quantity squared for no reason|\n",
      "+----------+------+--------+------------------------------+\n",
      "|     apple|   red|       3|                           9.0|\n",
      "|    banana|yellow|       5|                          25.0|\n",
      "|strawberry|   red|       7|                          49.0|\n",
      "+----------+------+--------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.color == 'red').show()\n",
    "\n",
    "df.withColumn('quantity squared for no reason', pow(df.quantity, 2)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c5b66",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b4c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 rows\n",
      "+----------+------+--------+\n",
      "|     fruit| color|quantity|\n",
      "+----------+------+--------+\n",
      "|     apple|   red|       3|\n",
      "|    banana|yellow|       5|\n",
      "|strawberry|   red|       7|\n",
      "+----------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.count(), 'rows')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec23e81",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7986181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|avg(quantity)|sum(quantity)|\n",
      "+-------------+-------------+\n",
      "|          5.0|           15|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, avg\n",
    "\n",
    "df.select(avg(df.quantity), sum(df.quantity)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04bdab",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d74d635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/foo.csv'\n",
    "\n",
    "df.write.csv(file_path, header=True, mode='overwrite') # 'overwrite' if the file alr exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1295d3",
   "metadata": {},
   "source": [
    "Question 5\n",
    "\n",
    "[Relevant StackOverflow post](https://stackoverflow.com/questions/48927271/count-number-of-words-in-a-spark-dataframe)\n",
    "\n",
    "`read.text()` will read the text file into a DataFrame. Each line will be stored in a separate row (as a string).\n",
    "\n",
    "[`functions.split()`](https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.functions.split) will split each line into an array (`Row`) of words.\n",
    "[`functions.size()`](https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.functions.size) will measure the size of this `Row` instance for each line. \n",
    "\n",
    "Finally sum the word-counts for all individual lines using [`functions.sum()`](https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.functions.size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(words)|\n",
      "+----------+\n",
      "|       256|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/24 12:40:42 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size, split, sum\n",
    "\n",
    "file_path = 'data/shakespeare.txt'\n",
    "\n",
    "df = spark.read.text(file_path) \n",
    "\n",
    "df = df.withColumn('words', size(split(df.value, ' '))) # append a column for words\n",
    "df.select(sum(df.words)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
