{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Covertype dataset](https://archive.ics.uci.edu/dataset/31/covertype) on UCI ML Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 12:00:15 WARN Utils: Your hostname, Ambujs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.86.1.175 instead (on interface en0)\n",
      "24/11/26 12:00:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/26 12:00:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/26 12:00:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\"Elevation\", \"Aspect\", \"Slope\", \\\n",
    "\"Horizontal_Distance_To_Hydrology\", \\\n",
    "\"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
    "\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\", \\\n",
    "\"Horizontal_Distance_To_Fire_Points\"] + \\\n",
    "[f\"Wilderness_Area_{i}\" for i in range(4)] + \\\n",
    "[f\"Soil_Type_{i}\" for i in range(40)] + \\\n",
    "[\"Cover_Type\"]\n",
    "\n",
    "# alternatively, colnames = df.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data/covertype/covtype.data.gz\", header=False, inferSchema=True)\n",
    "df = df.toDF(*colnames)\n",
    "\n",
    "df = df.na.drop() # handle missing values lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 12:00:20 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Elevation: int, Aspect: int, Slope: int, Horizontal_Distance_To_Hydrology: int, Vertical_Distance_To_Hydrology: int, Horizontal_Distance_To_Roadways: int, Hillshade_9am: int, Hillshade_Noon: int, Hillshade_3pm: int, Horizontal_Distance_To_Fire_Points: int, Wilderness_Area_0: int, Wilderness_Area_1: int, Wilderness_Area_2: int, Wilderness_Area_3: int, Soil_Type_0: int, Soil_Type_1: int, Soil_Type_2: int, Soil_Type_3: int, Soil_Type_4: int, Soil_Type_5: int, Soil_Type_6: int, Soil_Type_7: int, Soil_Type_8: int, Soil_Type_9: int, Soil_Type_10: int, Soil_Type_11: int, Soil_Type_12: int, Soil_Type_13: int, Soil_Type_14: int, Soil_Type_15: int, Soil_Type_16: int, Soil_Type_17: int, Soil_Type_18: int, Soil_Type_19: int, Soil_Type_20: int, Soil_Type_21: int, Soil_Type_22: int, Soil_Type_23: int, Soil_Type_24: int, Soil_Type_25: int, Soil_Type_26: int, Soil_Type_27: int, Soil_Type_28: int, Soil_Type_29: int, Soil_Type_30: int, Soil_Type_31: int, Soil_Type_32: int, Soil_Type_33: int, Soil_Type_34: int, Soil_Type_35: int, Soil_Type_36: int, Soil_Type_37: int, Soil_Type_38: int, Soil_Type_39: int, Cover_Type: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = df.randomSplit([0.9, 0.1])\n",
    "train_data.cache()\n",
    "test_data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse all those columns into a \"feature vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------+\n",
      "|featureVector                                                                                     |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1859.0,18.0,12.0,67.0,11.0,90.0,211.0,215.0,139.0,792.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1860.0,18.0,13.0,95.0,15.0,90.0,210.0,213.0,138.0,780.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1861.0,35.0,14.0,60.0,11.0,85.0,218.0,209.0,124.0,832.0,1.0,1.0])|\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "input_cols = colnames[:-1]\n",
    "vector_assembler = VectorAssembler(inputCols=input_cols, outputCol=\"featureVector\")\n",
    "\n",
    "assembled_train_data = vector_assembler.transform(train_data)\n",
    "assembled_test_data = vector_assembler.transform(test_data)\n",
    "\n",
    "assembled_train_data.select(\"featureVector\").show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 12:00:27 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DecisionTreeClassificationModel: uid=DecisionTreeClassifier_1f71dc5f679b, depth=5, numNodes=43, numClasses=8, numFeatures=54\\n  If (feature 0 <= 3048.5)\\n   If (feature 0 <= 2561.5)\\n    If (feature 10 <= 0.5)\\n     If (feature 0 <= 2450.5)\\n      If (feature 3 <= 15.0)\\n       Predict: 4.0\\n      Else (feature 3 > 15.0)\\n       Predict: 3.0\\n     Else (feature 0 > 2450.5)\\n      If (feature 17 <= 0.5)\\n       Predict: 2.0\\n      Else (feature 17 > 0.5)\\n       Predict: 3.0\\n    Else (feature 10 > 0.5)\\n     Predict: 2.0\\n   Else (feature 0 > 2561.5)\\n    If (feature 0 <= 2952.5)\\n     If (feature 15 <= 0.5)\\n      If (feature 17 <= 0.5)\\n       Predict: 2.0\\n      Else (feature 17 > 0.5)\\n       Predict: 3.0\\n     Else (feature 15 > 0.5)\\n      Predict: 3.0\\n    Else (feature 0 > 2952.5)\\n     If (feature 3 <= 211.0)\\n      If (feature 36 <= 0.5)\\n       Predict: 2.0\\n      Else (feature 36 > 0.5)\\n       Predict: 1.0\\n     Else (feature 3 > 211.0)\\n      Predict: 2.0\\n  Else (feature 0 > 3048.5)\\n   If (feature 0 <= 3323.5)\\n    If (feature 7 <= 240.5)\\n     Predict: 1.0\\n    Else (feature 7 > 240.5)\\n     If (feature 3 <= 316.0)\\n      Predict: 1.0\\n     Else (feature 3 > 316.0)\\n      If (feature 0 <= 3215.5)\\n       Predict: 2.0\\n      Else (feature 0 > 3215.5)\\n       Predict: 1.0\\n   Else (feature 0 > 3323.5)\\n    If (feature 12 <= 0.5)\\n     If (feature 3 <= 298.5)\\n      If (feature 8 <= 184.5)\\n       Predict: 7.0\\n      Else (feature 8 > 184.5)\\n       Predict: 1.0\\n     Else (feature 3 > 298.5)\\n      Predict: 1.0\\n    Else (feature 12 > 0.5)\\n     If (feature 45 <= 0.5)\\n      If (feature 7 <= 246.5)\\n       Predict: 7.0\\n      Else (feature 7 > 246.5)\\n       Predict: 1.0\\n     Else (feature 45 > 0.5)\\n      If (feature 5 <= 993.5)\\n       Predict: 7.0\\n      Else (feature 5 > 993.5)\\n       Predict: 1.0\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(seed=1234, labelCol=colnames[-1], featuresCol=\"featureVector\", \n",
    "    predictionCol=\"prediction\")\n",
    "\n",
    "model = classifier.fit(assembled_train_data)\n",
    "model.toDebugString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7001498992057065\n",
      "f1 0.6830076777165297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "predictions = model.transform(assembled_test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=colnames[-1], predictionCol=\"prediction\")\n",
    "accuracy = evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "f1 = evaluator.setMetricName(\"f1\").evaluate(predictions)\n",
    "\n",
    "print(\"accuracy\", accuracy)\n",
    "print(\"f1\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+----+---+----+\n",
      "|Cover_Type|  1.0|  2.0| 3.0|4.0| 7.0|\n",
      "+----------+-----+-----+----+---+----+\n",
      "|         1|14741| 5833|  27|  0| 432|\n",
      "|         2| 6001|21851| 497| 13|  63|\n",
      "|         3|    0|  594|2939| 80|   0|\n",
      "|         4|    0|    1| 171|105|   0|\n",
      "|         5|    1|  819|  78|  0|   0|\n",
      "|         6|    0|  663|1006| 67|   0|\n",
      "|         7| 1052|    2|   3|  0|1000|\n",
      "+----------+-----+-----+----+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = predictions.groupBy(colnames[-1]) \\\n",
    "    .pivot(\"prediction\") \\\n",
    "    .count() \\\n",
    "    .fillna(0) \\\n",
    "    .orderBy(colnames[-1])\n",
    "\n",
    "confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Elevation', np.float64(0.8033405065427717)),\n",
       " ('Horizontal_Distance_To_Hydrology', np.float64(0.04116751288797765)),\n",
       " ('Wilderness_Area_0', np.float64(0.03182246571962519)),\n",
       " ('Soil_Type_3', np.float64(0.030906107785844746)),\n",
       " ('Hillshade_Noon', np.float64(0.02837865741579338))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = model.featureImportances.toArray()\n",
    "A = list(zip(input_cols, importances))\n",
    "A.sort(key=lambda x: x[1], reverse=True)\n",
    "A[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Not in manual again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "assembler = VectorAssembler(inputCols=colnames[:-1], outputCol=\"featureVector\")\n",
    "classifier = DecisionTreeClassifier(featuresCol=\"featureVector\", labelCol=colnames[-1], predictionCol=\"prediction\")\n",
    "pipeline = Pipeline(stages=[assembler, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TrainValidationSplit` is like `CrossValidator`, but it performs the split only once. Good for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 12:00:50 WARN DAGScheduler: Broadcasting large task binary with size 1011.7 KiB\n",
      "24/11/26 12:00:50 WARN DAGScheduler: Broadcasting large task binary with size 1350.5 KiB\n",
      "24/11/26 12:00:51 WARN DAGScheduler: Broadcasting large task binary with size 1769.1 KiB\n",
      "24/11/26 12:00:51 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/11/26 12:00:52 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/11/26 12:00:52 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/11/26 12:00:53 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/11/26 12:00:54 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "24/11/26 12:00:54 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/11/26 12:01:04 WARN DAGScheduler: Broadcasting large task binary with size 1294.8 KiB\n",
      "24/11/26 12:01:05 WARN DAGScheduler: Broadcasting large task binary with size 1681.9 KiB\n",
      "24/11/26 12:01:06 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/11/26 12:01:08 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/11/26 12:01:10 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/11/26 12:01:12 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "24/11/26 12:01:14 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "24/11/26 12:01:16 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "24/11/26 12:01:33 WARN DAGScheduler: Broadcasting large task binary with size 1081.1 KiB\n",
      "24/11/26 12:01:33 WARN DAGScheduler: Broadcasting large task binary with size 1489.2 KiB\n",
      "24/11/26 12:01:33 WARN DAGScheduler: Broadcasting large task binary with size 1999.4 KiB\n",
      "24/11/26 12:01:34 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/11/26 12:01:35 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/11/26 12:01:35 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "24/11/26 12:01:36 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "24/11/26 12:01:37 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "24/11/26 12:01:37 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "24/11/26 12:01:41 WARN DAGScheduler: Broadcasting large task binary with size 1016.7 KiB\n",
      "24/11/26 12:01:42 WARN DAGScheduler: Broadcasting large task binary with size 1104.6 KiB\n",
      "24/11/26 12:01:42 WARN DAGScheduler: Broadcasting large task binary with size 1175.3 KiB\n",
      "24/11/26 12:01:42 WARN DAGScheduler: Broadcasting large task binary with size 1227.4 KiB\n",
      "24/11/26 12:01:48 WARN DAGScheduler: Broadcasting large task binary with size 1090.5 KiB\n",
      "24/11/26 12:01:50 WARN DAGScheduler: Broadcasting large task binary with size 1478.1 KiB\n",
      "24/11/26 12:01:51 WARN DAGScheduler: Broadcasting large task binary with size 1949.8 KiB\n",
      "24/11/26 12:01:53 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "24/11/26 12:01:55 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "24/11/26 12:01:57 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/11/26 12:01:59 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/11/26 12:02:01 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n",
      "24/11/26 12:02:03 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/11/26 12:02:14 WARN DAGScheduler: Broadcasting large task binary with size 1067.9 KiB\n",
      "24/11/26 12:02:14 WARN DAGScheduler: Broadcasting large task binary with size 1493.9 KiB\n",
      "24/11/26 12:02:15 WARN DAGScheduler: Broadcasting large task binary with size 2038.4 KiB\n",
      "24/11/26 12:02:15 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/11/26 12:02:16 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/11/26 12:02:17 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/11/26 12:02:17 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "24/11/26 12:02:18 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "grid = ParamGridBuilder() \\\n",
    "    .addGrid(classifier.impurity, [\"gini\", \"entropy\"]) \\\n",
    "    .addGrid(classifier.maxDepth, [1, 20]) \\\n",
    "    .addGrid(classifier.maxBins, [40, 300]) \\\n",
    "    .addGrid(classifier.minInfoGain, [0.0, 0.05]) \\\n",
    "    .build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\", predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "\n",
    "validator = TrainValidationSplit(estimator=pipeline, evaluator=evaluator, \n",
    "    estimatorParamMaps=grid)\n",
    "validator_model = validator.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9094465626981884,\n",
       " {Param(parent='DecisionTreeClassifier_bb96282e352a', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "  Param(parent='DecisionTreeClassifier_bb96282e352a', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "  Param(parent='DecisionTreeClassifier_bb96282e352a', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "  Param(parent='DecisionTreeClassifier_bb96282e352a', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = validator_model.getEstimatorParamMaps() # list of param maps for all models\n",
    "metrics = validator_model.validationMetrics \n",
    "\n",
    "metrics_and_params = list(zip(metrics, params))\n",
    "metrics_and_params.sort(key=lambda x: x[0], reverse=True)\n",
    "metrics_and_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 12:02:19 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9129895415151881"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(validator_model.bestModel.transform(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage for `RandomForestClassifier` is the exact same. Even the hyperparameters are the same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
