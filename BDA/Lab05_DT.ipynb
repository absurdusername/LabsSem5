{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Covertype dataset](https://archive.ics.uci.edu/dataset/31/covertype) on UCI ML Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data/covertype/covtype.data.gz\", header=False, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, _c1: int, _c2: int, _c3: int, _c4: int, _c5: int, _c6: int, _c7: int, _c8: int, _c9: int, _c10: int, _c11: int, _c12: int, _c13: int, _c14: int, _c15: int, _c16: int, _c17: int, _c18: int, _c19: int, _c20: int, _c21: int, _c22: int, _c23: int, _c24: int, _c25: int, _c26: int, _c27: int, _c28: int, _c29: int, _c30: int, _c31: int, _c32: int, _c33: int, _c34: int, _c35: int, _c36: int, _c37: int, _c38: int, _c39: int, _c40: int, _c41: int, _c42: int, _c43: int, _c44: int, _c45: int, _c46: int, _c47: int, _c48: int, _c49: int, _c50: int, _c51: int, _c52: int, _c53: int, _c54: int]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = df.randomSplit([0.9, 0.1])\n",
    "train_data.cache()\n",
    "test_data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse all those columns into a \"feature vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       featureVector|\n",
      "+--------------------+\n",
      "|(54,[0,1,2,3,4,5,...|\n",
      "|(54,[0,1,2,3,4,5,...|\n",
      "|(54,[0,1,2,3,4,5,...|\n",
      "|(54,[0,1,2,3,4,5,...|\n",
      "|(54,[0,1,2,3,4,5,...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "input_cols = df.schema.names[:-1]\n",
    "vector_assembler = VectorAssembler(inputCols=input_cols, outputCol=\"featureVector\")\n",
    "\n",
    "assembled_train_data = vector_assembler.transform(train_data)\n",
    "assembled_test_data = vector_assembler.transform(test_data)\n",
    "\n",
    "assembled_train_data.select(\"featureVector\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_0a499d9ff701, depth=5, numNodes=43, numClasses=8, numFeatures=54\n",
      "  If (feature 0 <= 3048.5)\n",
      "   If (feature 0 <= 2561.5)\n",
      "    If (feature 10 <= 0.5)\n",
      "     If (feature 0 <= 2450.0)\n",
      "      If (feature 3 <= 15.0)\n",
      "       Predict: 4.0\n",
      "      Else (feature 3 > 15.0)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 2450.0)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "    Else (feature 10 > 0.5)\n",
      "     Predict: 2.0\n",
      "   Else (feature 0 > 2561.5)\n",
      "    If (feature 0 <= 2952.5)\n",
      "     If (feature 15 <= 0.5)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "     Else (feature 15 > 0.5)\n",
      "      Predict: 3.0\n",
      "    Else (feature 0 > 2952.5)\n",
      "     If (feature 3 <= 186.0)\n",
      "      If (feature 36 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 36 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 186.0)\n",
      "      Predict: 2.0\n",
      "  Else (feature 0 > 3048.5)\n",
      "   If (feature 0 <= 3323.5)\n",
      "    If (feature 7 <= 239.5)\n",
      "     Predict: 1.0\n",
      "    Else (feature 7 > 239.5)\n",
      "     If (feature 3 <= 321.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 3 > 321.0)\n",
      "      If (feature 0 <= 3215.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 3215.5)\n",
      "       Predict: 1.0\n",
      "   Else (feature 0 > 3323.5)\n",
      "    If (feature 12 <= 0.5)\n",
      "     If (feature 4 <= 42.5)\n",
      "      If (feature 7 <= 238.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 7 > 238.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 4 > 42.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 12 > 0.5)\n",
      "     If (feature 45 <= 0.5)\n",
      "      If (feature 7 <= 247.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 7 > 247.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 45 > 0.5)\n",
      "      If (feature 5 <= 983.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 5 > 983.5)\n",
      "       Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "labelCol = df.schema.names[-1]\n",
    "classifier = DecisionTreeClassifier(seed=1234, labelCol=labelCol, featuresCol=\"featureVector\",\n",
    "predictionCol=\"prediction\")\n",
    "\n",
    "model = classifier.fit(assembled_train_data)\n",
    "print(model.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7011925453012339\n",
      "f1 0.6831750961501089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "predictions = model.transform(assembled_test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=labelCol, predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "f1 = evaluator.setMetricName(\"f1\").evaluate(predictions)\n",
    "\n",
    "print(\"accuracy\", accuracy)\n",
    "print(\"f1\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+----+---+----+\n",
      "|_c54|  1.0|  2.0| 3.0|4.0| 7.0|\n",
      "+----+-----+-----+----+---+----+\n",
      "|   1|14957| 5878|  17|  0| 430|\n",
      "|   2| 5872|21842| 462| 13|  49|\n",
      "|   3|    0|  606|2812| 82|   0|\n",
      "|   4|    0|    6| 181|101|   0|\n",
      "|   5|    1|  909|  78|  0|   0|\n",
      "|   6|    0|  711|1023| 52|   0|\n",
      "|   7|  985|    3|   6|  0|1035|\n",
      "+----+-----+-----+----+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = predictions.groupBy(labelCol) \\\n",
    "    .pivot(\"prediction\") \\\n",
    "    .count() \\\n",
    "    .na.fill(0) \\\n",
    "    .orderBy(labelCol)\n",
    "\n",
    "confusion_matrix.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
